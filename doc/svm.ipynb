{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Predict the default of Credit Card holder</center></h1>\n",
    "<h2><center>Group 1: \n",
    "Li, Qiao; Shu, Chuyun; Xia, Zhihang; Yu, Shuqi; Yuan, Serena; Zhang, Renyin </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This research aimed at the case of customers’ default payments in Taiwan and compares the predictive accuracy of probability of default among different models. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "Our study took payment data in October, 2005, from an\n",
    "important bank (a cash and credit card issuer) in Taiwan\n",
    "and the targets were credit card holders of the bank.\n",
    "Among the total 25,000 observations, 5529 observations\n",
    "(22.12%) are the cardholders with default payment. This\n",
    "research employed a binary variable – default payment\n",
    "(Yes = 1, No = 0), as the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "Following 23 variables as explanatory variables:\n",
    " \n",
    " X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    " \n",
    " X2: Gender (1 = male; 2 = female).\n",
    " \n",
    " X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "\n",
    " X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    " \n",
    " X5: Age (year).\n",
    " \n",
    " X6–X11: History of past payment. We tracked the past monthly payment records (from April to September,2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August,2005;...;X11 = the repayment status in April, 2005.\n",
    "The measurement scale for the repayment status is:\n",
    "1 = pay duly; 1 = payment delay for one month;2 = payment delay for two months; ...; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    " \n",
    " X12–X17: Amount of bill statement (NT dollar).(X12 = amount of bill statement in September,2005; X13 = amount of bill statement in August,2005 ;...; X17 = amount of bill statement in April,2005.)\n",
    " \n",
    " X18–X23: Amount of previous payment (NT dollar).(X18 = amount paid in September, 2005; X19 = amount paid in August, 2005;...;X23 = amount paid in April,2005.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up the environment\n",
    "First, make sure you have python installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have python installed - please follow this [link](https://realpython.com/installing-python/) for instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell below will start the installation of required python libraries, assuming you have python already installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy \n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "!pip install iplot\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the librarys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import smote_variants as sv\n",
    "import imbalanced_databases as imbd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import *\n",
    "%matplotlib inline\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Load Default of Credit Card Clients data\n",
    "The data was randomly divided into two groups, one for model training and the other to validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30001, 25)\n"
     ]
    }
   ],
   "source": [
    "df_credit_raw = pd.read_excel (\"../data/default of credit card clients.xls\")\n",
    "print (df_credit_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19394</td>\n",
       "      <td>19619</td>\n",
       "      <td>20024</td>\n",
       "      <td>2500</td>\n",
       "      <td>1815</td>\n",
       "      <td>657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>542653</td>\n",
       "      <td>483003</td>\n",
       "      <td>473944</td>\n",
       "      <td>55000</td>\n",
       "      <td>40000</td>\n",
       "      <td>38000</td>\n",
       "      <td>20239</td>\n",
       "      <td>13750</td>\n",
       "      <td>13770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>-159</td>\n",
       "      <td>567</td>\n",
       "      <td>380</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>1687</td>\n",
       "      <td>1542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>140000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12211</td>\n",
       "      <td>11793</td>\n",
       "      <td>3719</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>13912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1 X2 X3 X4  X5  X6  X7  X8  X9 X10  ...     X15     X16     X17  \\\n",
       "ID                                           ...                           \n",
       "1    20000  2  2  1  24   2   2  -1  -1  -2  ...       0       0       0   \n",
       "2   120000  2  2  2  26  -1   2   0   0   0  ...    3272    3455    3261   \n",
       "3    90000  2  2  2  34   0   0   0   0   0  ...   14331   14948   15549   \n",
       "4    50000  2  2  1  37   0   0   0   0   0  ...   28314   28959   29547   \n",
       "5    50000  1  2  1  57  -1   0  -1   0   0  ...   20940   19146   19131   \n",
       "6    50000  1  1  2  37   0   0   0   0   0  ...   19394   19619   20024   \n",
       "7   500000  1  1  2  29   0   0   0   0   0  ...  542653  483003  473944   \n",
       "8   100000  2  2  2  23   0  -1  -1   0   0  ...     221    -159     567   \n",
       "9   140000  2  3  1  28   0   0   2   0   0  ...   12211   11793    3719   \n",
       "10   20000  1  3  2  35  -2  -2  -2  -2  -1  ...       0   13007   13912   \n",
       "\n",
       "      X18    X19    X20    X21    X22    X23  Y  \n",
       "ID                                               \n",
       "1       0    689      0      0      0      0  1  \n",
       "2       0   1000   1000   1000      0   2000  1  \n",
       "3    1518   1500   1000   1000   1000   5000  0  \n",
       "4    2000   2019   1200   1100   1069   1000  0  \n",
       "5    2000  36681  10000   9000    689    679  0  \n",
       "6    2500   1815    657   1000   1000    800  0  \n",
       "7   55000  40000  38000  20239  13750  13770  0  \n",
       "8     380    601      0    581   1687   1542  0  \n",
       "9    3329      0    432   1000   1000   1000  0  \n",
       "10      0      0      0  13007   1122      0  0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit = df_credit_raw.iloc[1:]\n",
    "df_credit.set_index(\"ID\", inplace=True)\n",
    "print(df_credit.shape)\n",
    "df_credit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11',\n",
       "       'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20',\n",
       "       'X21', 'X22', 'X23'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data for training purpose\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_credit.loc[:, df_credit.columns != 'Y']\n",
    "y = df_credit['Y'].values.astype('int')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=0)\n",
    "X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>320000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13917</td>\n",
       "      <td>12125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1267</td>\n",
       "      <td>1700</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12887</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>6360</td>\n",
       "      <td>2620</td>\n",
       "      <td>5900</td>\n",
       "      <td>37084</td>\n",
       "      <td>5007</td>\n",
       "      <td>7096</td>\n",
       "      <td>2620</td>\n",
       "      <td>6000</td>\n",
       "      <td>17703</td>\n",
       "      <td>4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16219</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>87941</td>\n",
       "      <td>89737</td>\n",
       "      <td>95451</td>\n",
       "      <td>97379</td>\n",
       "      <td>3079</td>\n",
       "      <td>3185</td>\n",
       "      <td>3251</td>\n",
       "      <td>7200</td>\n",
       "      <td>3600</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1 X2 X3 X4  X5  X6  X7  X8  X9 X10  ...    X14    X15    X16  \\\n",
       "ID                                              ...                        \n",
       "6671   320000  1  1  2  26  -1   0   0   0   0  ...  13917  12125      0   \n",
       "12887  200000  1  1  1  40  -1  -1  -1  -1  -1  ...   6360   2620   5900   \n",
       "16219  120000  2  1  2  45   0   0   0   0   0  ...  87941  89737  95451   \n",
       "\n",
       "         X17   X18   X19   X20   X21    X22     X23  \n",
       "ID                                                   \n",
       "6671       0  1267  1700   243     0      0  220000  \n",
       "12887  37084  5007  7096  2620  6000  17703    4914  \n",
       "16219  97379  3079  3185  3251  7200   3600    3900  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>2.411645e-15</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>1.560310e-15</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>1.479724e-15</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X11</th>\n",
       "      <td>1.009262e-15</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X23</th>\n",
       "      <td>4.436798e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X15</th>\n",
       "      <td>3.557571e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X18</th>\n",
       "      <td>2.443323e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22</th>\n",
       "      <td>2.128691e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X20</th>\n",
       "      <td>1.895521e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>1.651642e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X19</th>\n",
       "      <td>1.291825e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X21</th>\n",
       "      <td>1.280920e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X16</th>\n",
       "      <td>9.948061e-17</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>7.640647e-17</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X17</th>\n",
       "      <td>-7.741493e-17</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>-8.479328e-17</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>-9.501659e-17</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X12</th>\n",
       "      <td>-1.031212e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>-2.287707e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>-2.548609e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>-7.345143e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>-8.024322e-16</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>-1.485411e-15</td>\n",
       "      <td>1.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean       std\n",
       "X9   2.411645e-15  1.000021\n",
       "X10  1.560310e-15  1.000021\n",
       "X7   1.479724e-15  1.000021\n",
       "X11  1.009262e-15  1.000021\n",
       "X23  4.436798e-16  1.000021\n",
       "X15  3.557571e-16  1.000021\n",
       "X18  2.443323e-16  1.000021\n",
       "X22  2.128691e-16  1.000021\n",
       "X20  1.895521e-16  1.000021\n",
       "X8   1.651642e-16  1.000021\n",
       "X19  1.291825e-16  1.000021\n",
       "X21  1.280920e-16  1.000021\n",
       "X16  9.948061e-17  1.000021\n",
       "X14  7.640647e-17  1.000021\n",
       "X17 -7.741493e-17  1.000021\n",
       "X13 -8.479328e-17  1.000021\n",
       "X4  -9.501659e-17  1.000021\n",
       "X12 -1.031212e-16  1.000021\n",
       "X1  -2.287707e-16  1.000021\n",
       "X5  -2.548609e-16  1.000021\n",
       "X6  -7.345143e-16  1.000021\n",
       "X2  -8.024322e-16  1.000021\n",
       "X3  -1.485411e-15  1.000021"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = pd.DataFrame(ss.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test = ss.transform(X_test)\n",
    "X_train.agg(['mean','std']).T.sort_values('mean',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X6                             :  0.640\n",
      "X7                             :  0.100\n",
      "X8                             :  0.086\n",
      "X14                            :  0.078\n",
      "X13                            :  0.070\n",
      "X5                             :  0.064\n",
      "X10                            :  0.058\n",
      "X16                            :  0.043\n",
      "X9                             :  0.017\n",
      "X11                            :  0.011\n",
      "X15                            :  0.000\n",
      "X17                            :  0.000\n",
      "X2                             : -0.045\n",
      "X23                            : -0.045\n",
      "X22                            : -0.062\n",
      "X4                             : -0.070\n",
      "X21                            : -0.072\n",
      "X3                             : -0.090\n",
      "X1                             : -0.099\n",
      "X20                            : -0.112\n",
      "X19                            : -0.156\n",
      "X18                            : -0.235\n",
      "X12                            : -0.295\n",
      "\n",
      "Columns to remove: Index(['X15', 'X17'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# with LASSO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression(C=0.1, penalty=\"l1\", solver=\"liblinear\", random_state=0)\n",
    "logr.fit(X_train, y_train)\n",
    "sorted_tuples = sorted(list(zip(X_train.columns.values,logr.coef_[0])),key=lambda x:x[1],reverse=True)\n",
    "for feature,coef in sorted_tuples:\n",
    "    print(f'{feature:30s} : {coef: 0.3f}')\n",
    "\n",
    "print(f'\\nColumns to remove: {X_train.columns[logr.coef_[0] == 0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X6     0.096\n",
       "X5     0.067\n",
       "X12    0.060\n",
       "X1     0.059\n",
       "X13    0.055\n",
       "X14    0.052\n",
       "X16    0.050\n",
       "X18    0.050\n",
       "X15    0.050\n",
       "X17    0.049\n",
       "X19    0.048\n",
       "X7     0.047\n",
       "X20    0.046\n",
       "X23    0.046\n",
       "X22    0.044\n",
       "X21    0.043\n",
       "X8     0.028\n",
       "X10    0.022\n",
       "X3     0.021\n",
       "X9     0.020\n",
       "X11    0.020\n",
       "X4     0.014\n",
       "X2     0.012\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree based model feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=123).fit(X_train,y_train)\n",
    "rf.feature_importances_ # (normalized) total reduction of function measuring impurity\n",
    "feature_importances = pd.Series(rf.feature_importances_,index=X_train.columns)\n",
    "feature_importances.sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAF3CAYAAABnkcdUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABBi0lEQVR4nO3df5hdZX3u//edsSaMSqyCEokYOSC2ljbixINK0wDRHhGwQE6otUjMqTERaSlO0wCCFtQQwRjtKcRoYSBWA0UsBIwYEnJygujpYJAfaijEyA+JCpoYkoiS3N8/1pqv22Ems/fsndkz2ffrutY1rGc9z7M+O+xr+LDyrM8j20RERERERO1GNTuAiIiIiIiRKsl0RERERMQgJZmOiIiIiBikJNMREREREYOUZDoiIiIiYpCSTEdEREREDFKS6YgYkSR9VJL7OG5v8H3eKOmjjZyzHuVn/GCz46iGpOeX/54mNjuWiIi95XnNDiAiog5bgf/RR1sjvRH4CPDRBs/bCp5P8We3CbinqZFEROwlSaYjYiR71va3mh1ELSTtZ3tns+PY2yTt1+wYIiKGQpZ5RMQ+S9LfSHpA0jOSfiRpbq/rb5J0s6QfS9ou6R5J7664PgP45/Kfe5aRrCnPuyR195pvQtnnxIo2SzpX0iJJPwPuK9vHSPqkpEfL+L4r6YRBfMY1km6Q9F5JP5T0tKSlkkaXS1T+X9m2RtIhfcT6V2X/bZJ+KukjfdzjOEnflvQrST+RdIWkF1Zcn1LO9efln+fTwP8GtpVdrq7485tQjrlU0n1lbI9J+jdJB/W67yZJl0v6+7LPLyQtk/TiXv1eKulzkp4oY9wg6ZyK66MkzZP0UPln/aCkM2v9s46I6EueTEfEiCap9++xXbYt6R+ATwCfBNYAbwAukbTD9v8u+74KuBNYDPwKeAtF4rfb9peBW4FPAR8C3lSO+eUgwvwHYC1wBr99iHEDv11C8jAwHbhZUofte2qc/2jgAOBs4BDg08BO4L9TfP7twGeBJTx3WcxlwC3ANGAy8BFJT9r+FwBJfwh8HVgJnAa8ErgUOLSPuf4VuBpYRPHn+UVgNfAxij9LgCfKny+j+PfzY+BAij/j1ZKOtL2rYs7pwL3ALGA8sLAc94Eyvv0o/v2+DPgn4AfAYeXR45+BM4GLge8AbwWukvSU7Vv6+POMiKie7Rw5cuQYcQfFGmb3cUwF9geeBj7Sa8zFwGagrY/5RPGA4XPA6or2Dxa/Kp/Tvwvo7tU2oYzhxIo2A+t79Tu+bP+zXu1rgX8f4HMb+GDF+RpgCzC2ou36st/kirYPlG3tvWL9Rq/5Pw88Dowqz5cB/1X5Z0aR4Bp4U3k+pTz/dK+5Xli2zxjgM7UBB/cR8yaK/9F4XkXbImBzxfn7gd3AxH7mPqy8fmav9muB/2z29zhHjhwj/8gyj4gYybYCk3od36Z4ivwC4N8lPa/noHhK+nKKJ5xI+n1Jn5X0I+A35TELeE2D47y11/lUiqT+zl7xrQI6BjF/t+3KFy8fAn4NrOvVBvCKXmO/2uv8xrLP+PL8jcBX/btPi78CPAsc02ts78/ZL0lvl/RNSVvLuR4rL/X+s7/D9rMV598DXibp+eX5cRT/s3JPP7c6niKZ/moff9YTJbVVG3NERF+yzCMiRrJnbXf3bpR0QPmPD/Qz7pXAjyieLh8NXEKRpP0SmAO8s8Fx/qTX+QHAQRTJe2+7+mgbyJZe578Gttne3asNYEyvvj/t53wc8Ej583fit71L0lPAS3qN7f05+yRpEnAzRSJ/aXlPA9/qI74tvc5/TfG3CM8v//ml/HbpSF8OoHjy3V+Vl3H8NpGPiKhZkumI2Bf9vPx5In0neBskjQHeQbFkYnHPBUnV/o3drygSukq9k8se7iO+x4G/qPJee9PL+jl/ouLn7/Qpn+a+lN/+Offo/Tn7cwrwM+B02y7nfFW1AffyFL+7Prq3n1M8+X4LxRPq3nr/z0RERE2STEfEvuguihfwXmG7z6UHksZSPLF8pqLtRcDJ/G5S+Ovy2hjbv6pofwyY0Kv9rVXGt4rihbunbf+gyjF7yynAlRXnp1Ik0D1Pa78NnCLp/IqlHqdS/PejchlJX/p7Gr4f8JueRLr0bgZnFfA/Jf2x7Xv7uL6a4t/zWNsrB3mPiIh+JZmOiH2O7S0qdi38TPnEcy1FFY3XAMfaPsX2Vkn/CVwk6ZcUTy3nUSwH2L9iup5k9+8krQZ+aXsD8B8ULzR+QVIX8HrgvVWGuBK4DVgpaQHFcpT9gYnAGNvnDeqDD87rJH2OYh30ZOB/AX9XsUTkY8B64D8kXUmxlnoBcJvtu/Y0se1fS/ohMF3S/RRP8++l+PznSFoELAfeDPz1IOO/FjgL+Eb573wD8GrgNbbn2d4gaTGwTNIngW6K5P51ZZ+/GeR9IyKA1JmOiH2U7U9SvEz4duAm4MsUTz//b0W3vwJ+SJGQfYYioby211T/l6J83N9RPKX9XDn//cBMipcdbwb+rDyvJjZTPN29CjiHIrH+XDnXQE97G20uRSL/FYrKGJdQ1IjuifUBij/Dl1G8nPgxij/LaVXOP5ti3fLtwH9S/G3B14B/pCi11/Nnd2K/M+xB+bcCx1Ek5RcDK8rP9OOKbmeVn+s9wNco1sq/g+J/siIi6qLf/Vu2iIhoBeXmKT8ETnJqLUdEDFqeTEdEREREDFKS6YiIiIiIQcoyj4iIiIiIQcqT6YiIiIiIQUoyHRERERExSCOmzvQBBxzgCRMmNDuMiIhha/fuojT0qFF5ThIRMVh33333k7YPrLb/iEmmJ0yYQHd3d7PDiIiIiIh9mKQf1dI/jy8iIvYRV1xxBVdccUWzw4iIaCl1P5mWNApYA2yxfXJFezvFFrSrbc8p2/4c+CjwJ8CvgbttH1/Nfe57fCsT5t1ab7gREfuszV+6EoBPPvKqJkcSETF4my59R7NDqEndT6Zt7wZmAMdJqtxKdwFFst4JIOkvgGXAUuD1FNvmXlXv/SMiIiIimqUha6Ztb5TUCSyStAo4DJgDTLG9XVIb8Flgru3PVwz9fiPuHxERERHRDA1bM217MXAXxZPnq4GFtteVl98AvBJ4RtJ3JG2W9A1Jr2/U/SMiIiIihlqjX0CcDRwDPANcWNF+aPnzEuATwDuAx4D/I+kV/U0maZakbkndu3ZsbXCoERERERH1aXRpvJnATmA8RQLds4yjJ2n/uO0boEiUganAGRTrq5/D9hJgCcDocYdn3/OIiD046K8ubXYIEREtp2FPpiVNAuYB04CVQFe5VhrgifLn93r6234W+C/gkEbFEBERERExlBryZFrSGOBaoMv2CknrgQeAucB84G6KpR9HAOvKMaOA/wbcVs09jjx4LN0jrFRKRMRQuvzyywHo7OxsciQREa2jUU+m5wNjgHMBbG8GzgI+KumPbP8SWAz8k6Q/l3QE8Bng94EvNiiGiIiWdsstt3DLLbc0O4yIiJbSiE1bJgNnA1Ntb+tpt71M0qkUyz2OBv6BYqOWa4B24DvAsbZ/XG8MERERERHNUHcybXttf/PYnt6raW55RERERESMeI0ujRcRERER0TIaXRovIiKaZL/99mt2CBERLSfJdETEPmLFihXNDiEiouU04gXEUcAaYIvtkyva24H1wGrbcyRtAl7Va/gC2/Oquc99j29lwrxb6w03IiJixNiUkrARw17da6Zt7wZmAMdJmllxaQFFsl5Z8PRiYFzF8bF67x8REYUtd36ZLXd+udlhRES0lIYs87C9UVInsEjSKuAwYA4wxfb2iq7byhrUERHRYL/60XeLf3jLu5obSEREC2lYNQ/bi4G7gKXA1cBC2+t6deuU9JSkeyRdIOn5jbp/RERERMRQa/QLiLOBh8vjwl7XPkuxhvop4I3ApcCrgb/pbzJJs4BZAG37H9jgUCMiIiIi6tPoZHomsBMYDxwKfL/ngu2FFf3ulfRL4DpJ/2j7qb4ms70EWAIwetzhbnCsERERERF1adgyD0mTgHnANGAlxTbibXsY8u3y52GNiiEiopW17bc/bfvt3+wwIiJaiuz6H/hKGkOxhGOd7fdJOgh4ALjc9vx+xrwT+A/gVbYfGegeHR0d7u7urjvWiIiIiIj+SLrbdke1/Ru1zGM+MAY4F8D2ZklnAddIWg68CDgauAPYCkwCPg3cXE0iHRERERExHNW9zEPSZOBs4L22t/W0214G3AR0AbuA0yk2d/keRb3pzwOp3xQR0SDnnXce5513XrPDiIhoKXU/mba9tr95bE+vOD263ntFRET/7rrrrmaHEBHRchr2AmJERERERKtJMh0RERERMUhJpiMiIiIiBmnAZFrSKElrJd3cq71d0gZJV5bnF0i6U9J2Sc+ptyfpTyR9WdKjknaWY/9BUhL6iIgGGD9+POPHj292GBERLaWqOtOSDgXuBf7W9lVl2z8DJwB/bHu7pIspyt69BDjftnrNMROYCNwIPEKxpfjngfm2PzFQDKPHHe5xZy6q/pNFRETL2XTpO5odQkSMcHulzrTtjZI6gUWSVlHsWjgHmGJ7e9nnojKAaf3McVWvpo2SjgJOAwZMpiMiIiIihpuqS+PZXizpFGApMAFYaHtdnfffH/hFnXNERATw89uXAPCSqbOaHElEROuotc70bODh8riwnhuXT6VnAO/eQ59ZwCyAtv0PrOd2ERH7vF//dGOzQ4iIaDm1vvw3E9gJjAcOHexNJR0B3Aossv2V/vrZXmK7w3ZHW/vYwd4uIiIiImKvqDqZljQJmAdMA1YCXZLaar2hpNdSbCu+zPa8WsdHRERERAwXVSXTksYA1wJdtldQLL04DJhby80k/SFFIv3vtv++tlAjIiIiIoaXatdMzwfGAOcC2N4s6SzgGknLbd8v6RCKsngTACRNLMc+ZPtpSa8DVgN3AJ+QdFDP5LY3DxTAkQePpTsljyIi+jXr5zcBsCS/KyMihsyAdaYlTaZIgqfaXtPr2vUUa6ePBr4AnNnHFMfaXiPpo8BH+rpH75rUfeno6HB3d/dA3SIiIiIiBq3WOtNVbdoyHCSZjoiIiIi9rdZkOlt5R0TsI2bNmsWsWakxHRExlGqtMx0REcPUgw8+2OwQIiJaTp5MR0REREQMUt3JtKRRktZKurlXe7ukDZKuLM8vkHSnpO2SRsZC7YiIiIiIPah7mYft3ZJmAPdKmmn7qvLSgnL+zvJ8NHAjRZ3p82u9z32Pb2XCvFvrDTciYp+1eeNTAC31u3JTygBGRJM1ZM207Y2SOoFFklZRbOgyB5hie3vZ5yIASdMacc+IiPhdz3/Zoc0OISKi5TTsBUTbiyWdAiyl2Lhloe11jZo/IiL27CVTU8kjImKoNfoFxNnAMcAzwIX1TiZplqRuSd27dmytO7iIiIiIiEZqdDI9E9gJjKfYGbEutpfY7rDd0dY+tu7gIiL2ZU8uv5wnl1/e7DAiIlpKw5JpSZOAecA0YCXQJamtUfNHRMSePbvtSZ7d9mSzw4iIaCkNSaYljQGuBbpsrwBmUbyEOLcR80dEREREDEeNegFxPjAGOBfA9mZJZwHXSFpu+35JhwAvoXg5EUkTy7EP2X56oBscefBYulMCKSKiX1O+dRkAa/K7MiJiyNSdTEuaDJwNTLW9rafd9jJJp1Is9zgauBg4s2Lo+vLnsRS1pyMiIiIiRpRGbNqytr95bE+vOJ1RHhERsRe86U1vanYIEREtp2F1piMiornmz5/f7BAiIlpOo0vjRURERES0jCTTERH7iNNOO43TTjut2WFERLSULPOIiNhHPPXUU80OISKi5QyYTEsaRVFtY4vtkyva2ykqcqy2PUfSBcAJwESg3bZ6zXMg8EXgSOClwE+Bm4HzbQ+4V/h9j29lwrxbq/xYERGtZ/PGIpkeTr8rN6VMX0Ts4wZc5mF7N0UVjuMkzay4tIAiGe8sz0cDNwKL+plqN/BV4CTgNeWcxwOfrz3siIiIiIjmq2qZh+2NkjqBRZJWUexuOAeYYnt72eciAEnT+pnjKWBxRdOPJF0BnFdH/BERERERTVP1mmnbiyWdAiyl2MVwoe11g72xpFcApwL/Zw99ZlFsTU7b/gcO9lYRES1hzKv+pNkhRES0nFpfQJwNPFweFw7mhpK+DLwT2A+4BXhvf31tLwGWAIwed7gHc7+IiFbx4re8q9khRES0nFpL480EdgLjgUMHec+/B44C/qKcY9Eg54mIiIiIaKqqk2lJk4B5wDRgJdAlqa3WG9rebPsHtm8C3g/MkvTKWueJiIjf9ZPrP8JPrv9Is8OIiGgpVS3zkDQGuBbosr1C0nrgAWAuUM/+tT3J/OiBOh558Fi6U2IpIqJfU751GQBr8rsyImLIVLtmej4wBjgXiqfLks4CrpG03Pb9kg4BXkLxciKSJpZjH7L9tKQTKepL3w08DbwOuAz4lu2HGvR5IiIiIiKGTDWbtkwGzgam2t7W0257maRTKZZ7HA1cDJxZMXR9+fNYik1ffkXxAuMfUDyJfpSi7vSl9X+MiIiIiIihN2AybXttf/1sT684nVEe/c1zO3B7beFFRERERAxftZbGi4iIYerEE09sdggRES0nyXRExD6is7Oz2SFERLScWutMR0REREREqZoXEEdRvEC4xfbJFe3tFC8ZrrY9R9IFwAnARKDdtvYw5wHAd4FXAAfafnKgOO57fCsT5t06ULeIiJa1+UvzADjor2p7r3tTSulFRAzagE+mbe+meLHwOEkzKy4toEjGe/5ecTRwI9XtaHg1cE8NcUZEREREDDtVrZm2vVFSJ7BI0irgMGAOMMX29rLPRQCSpu1pLkl/B7QDH6d4kh0RERERMSJV/QKi7cWSTgGWUmzMstD2ulpuJun1wD8Ck4DDaxkbERERETHc1PoC4mzgGOAZ4MJaBkp6AfBl4Gzbj1c5Zpakbkndu3ZsrTHUiIiIiIi9q9bSeDOBncB44FDg+zWM/Sxwp+2vVDvA9hJgCcDocYe7hntFRLScF7z2T5sdQkREy6n6ybSkScA8YBqwkmIb8bYa7nU8MEPSs5KeBVaV7ZslfbyGeSIiog8vOuodvOioVOaIiBhKVT2ZljQGuBbosr1C0nrgAWAuML/Ke70NeH7F+STgKmAK8F8DDT7y4LF0p3xTRES/duzYAUB7e3uTI4mIaB3VLvOYD4wBzgWwvVnSWcA1kpbbvl/SIcBLKF5ORNLEcuxDtp+2/WDlhGWtaYAfVFNnOiIi9uyEE4oCSWvWrGluIBERLaSaTVsmA2cDU21v62m3vUzSqRTLPY4GLgbOrBi6vvx5LMWmLxERERER+5QBk2nba/vrZ3t6xemM8qiK7TVAv7skRkREREQMd7WWxouIiIiIiFKS6YiIiIiIQaq1znRERAxTM2bMaHYIEREtR/ae90KRNIriBcIttk+uaG+neMlwte05ki4ATgAmAu22+1wPLemvgU7gtcDTwNdsv2egQEePO9zjzlxUxUeKiIhNKSUaETEoku623VFt/wGXedjeTfFi4XGSZlZcWkDxZLuzPB8N3Ags2kNwfwtcBlwO/BFFpY+bqg02IiL6t2vHVnbt2NrsMCIiWkpVyzxsb5TUCSyStAo4DJgDTLG9vexzEYCkaX3NIenFFPWq/8L2yopL9w0+/IiI6PGz/yj20Drory5tciQREa2j6hcQbS8G7gKWAlcDC22vq+FebwPagJdL+p6kxyV9VdKhNUUcERERETFM1FrNYzZwDPAMcGGNYw8t7/dhip0UTwF+D7ijXH/9HJJmSeqW1J2/uoyIiIiI4abWZHomsBMYT5Ec13qv3wP+1vbXbf8/4N3Ay4CT+hpge4ntDtsdbe1ja7xdRERERMTeVXUyLWkSMA+YBqyk2Ea8rYZ7PVH+/F5Pg+2twI+BQ2qYJyIiIiJiWKjqBURJY4BrgS7bKyStBx4A5lK8VFiNO8ufRwCPlfO+EBgH/GigwUcePJbulHqKiOjXda9/GoDTT8/vyoiIoVLtpi3zgTEUa52xvVnSWcA1kpbbvl/SIcBLgAkAkiaWYx+y/bTtByXdBHxG0vuBXwD/BPwUuKVRHygiolWdfvrpzQ4hIqLlDLjMQ9Jk4Gzgvba39bTbXkZRI7pL0vOAiyk2cbms7LK+PCqLXp8BfAtYTvGkegxwvO0d9X+UiIjW9uijj/Loo482O4yIiJYy4A6Iw0VHR4e7u7ubHUZExLA1ZcoUANasWdPUOCIiRrKG74AYERERERF9SzIdERERETFISaYjIiIiIgZpwGoekkYBa4Attk+uaG+neMFwte05ki4ATgAmAu221cdckygqg7wBEHA3cF65gcse3ff4VibMu7WazxQR0ZImNDuAiIgWNGAybXu3pBnAvZJm2r6qvLSgHN9Zno8GbqRIvM/vPU9ZU/rrwK0U1UEALgBuk3RIZaWQiIio3Yc+9KFmhxAR0XKqqjNte6OkTmCRpFXAYcAcYIrt7WWfiwAkTetnmtdS1KH+iO0fln0vpNhS/AggpToiIupw0kknNTuEiIiWU/WaaduLgbuApcDVwELb62q41wbgZ8D/kjRa0mjgfcAjFLspRkREHTZs2MCGDRuaHUZEREupdgfEHrOBh8vjwloG2t4maQrFRi/nlc2bgLfa3tnXGEmzgFkAbfsfWGOoERGt5f3vfz+QOtMREUOp1moeM4GdwHjg0FoGStoPuIri6fbRwFsoXmC8SdIL+hpje4ntDtsdbe1jaww1IiIiImLvqjqZLitxzAOmASspthFvq+FefwX8N4ptyf/T9rfKtkOAU2qYJyIiIiJiWKgqmZY0BrgW6LK9gmLpxWHA3Bru1Q4Y2F3RtrtsS73riIiIiBhxql0zPR8YA5wLYHuzpLOAayQtt32/pEMoqnVMAJA0sRz7kO2nKZ5mXwZcIemzFAn0PGAXsHqgAI48eCzdl76j2s8VEdFypky5rNkhRES0nGo2bZlMURd6amUtaNvLJJ1KsdzjaOBi4MyKoevLn8cCa2z/QNJJwEco1k0buAd4u+3HGvFhIiJa2Yc//OFmhxAR0XJku9kxVKWjo8Pd3SlFHRERERF7j6S7bXdU2z9rlSMi9hH33HMP99xzT7PDiIhoKbXWmY6IiGHqnHPOAVJnOiJiKOXJdERERETEIA2YTEsaJWmtpJt7tbdL2iDpyvL8Akl3Stouqc+F2JLcxzG7MR8lIiIiImJoDbjMw/ZuSTOAeyXNtH1VeWlBOb6zPB8N3AisAc7fw5TvA26pON9aTaD3Pb6VCfNuraZrRERLmtDsACIiWlBVa6Ztb5TUCSyStIpiw5Y5wBTb28s+FwFImjbAdFtsb64j5oiIiIiIYaHqFxBtL5Z0CrCU4gHIQtvrBnHPz0haDPwQ+Fdgie3dA4yJiIgBfOITn2h2CBERLafWah6zgYfL48JB3O8i4A7gaeB44FPAAcDH+uosaRbF1uW07X/gIG4XEdE63vzmNzc7hIiIllNrMj0T2AmMBw4Fvl/LYNuXVJzeI6kNuIB+kmnbS4AlAKPHHT4ydpeJiGiSb37zm0CS6oiIoVR1Mi1pEjAPOJlivXSXpDfb3lXH/b8N7C/p5bZ/Usc8EREt7/zzi3e/U2c6ImLoVFVnWtIY4Fqgy/YKiqUXhwFz67z/ROBXwJY654mIiIiIGHLVPpmeD4wBzgWwvVnSWcA1kpbbvl/SIcBLKKszSZpYjn3I9tOSTgIOAu6iWCpyLHAxxQuIzwwUwJEHj6X70ndU/cEiIlrNlCmXNTuEiIiWM2AyLWkycDYw1fa2nnbbyySdSrHc42iKxPjMiqHry5/HUtSe/g3wAWAhxRPxjRQvJP5L/R8jIiIiImLoVbNpy9r++tmeXnE6ozz6m+frwNdrCy8iIiIiYviqtZpHREQMU4sWLWp2CBERLSfJdETEPmLixInNDiEiouVUVc0jIiKGv9tvv53bb7+92WFERLSUAZNpSaMkrZV0c6/2dkkbJF1Znl8g6U5J2yU9Z4MVSTMkuZ9jUuM+UkREa/rYxz7Gxz7W5x5YERGxl1TzAuJuSTOAeyXNtH1VeWlBOb6zPB8N3EhRueP8Pqa6jue+gHgZ8Bage6A47nt8KxPm3TpQt4iIlrEp5UIjIpquqjXTtjdK6gQWSVpFsWHLHGCK7e1ln4sAJE3rZ46dFPWlKfu1AycBn7SdrcIjIiIiYsSp+gVE24slnQIspdiYZaHtdXXcezrwAuDqOuaIiIiIiGiaWl9AnA0cAzwDXFjnvWcBt9h+or8OkmZJ6pbUvWvH1jpvFxERERHRWLWWxptJsVRjPHAo8P3B3FTS64A3AXtc8Gd7CbAEYPS4w7MUJCJiDz73uc81O4SIiJZTdTJdVtyYB5xMsV66S9Kbbe8axH1nAY+SHREjIhrmiCOOaHYIEREtp6plHpLGANcCXbZXUCTDhwFza71hOdcZwFW2d9c6PiIi+rZ8+XKWL1/e7DAiIlpKtU+m5wNjgHMBbG+WdBZwjaTltu+XdAjwEoqXE5E0sRz7kO2nK+aaBowFrqIGRx48lu6UgYqI6NenPvUpAE466aQmRxIR0ToGTKYlTQbOBqba3tbTbnuZpFMplnscDVwMnFkxdH3581iK2tM93gfcZvuROmOPiIiIiGiqajZtWdtfP9vTK05nlMdA8/1ZlbFFRERERAxrtZbGi4iIiIiIUpLpiIiIiIhBqrXOdEREDFNLly5tdggRES0nyXRExD7ila98ZbNDiIhoOdVU8xhFUY1ji+2TK9rbKSp2rLY9R9IFwAnARKDdtvqY63jgEuBI4GmK2tUX2H52oDjue3wrE+bdWs1niojYp2yqsizoddddB8Dpp5++N8OJiIgKA66ZLjdWmQEcJ2lmxaUFFMl4Z3k+GrgRWNTXPJL+GPga8A3g9cBfUuymeOngQo+IiEpXXnklV155ZbPDiIhoKVUt87C9UVInsEjSKordD+cAU2xvL/tcBCBpWj/T/CXwPdsfLc8fkjQXuF7SP1XWsI6IiIiIGAmqruZhezFwF7AUuBpYaHtdDfcaDfyqV9tOip0V31DDPBERERERw0KtpfFmA8cAzwAX1jj2NuC/SzpD0vMkHQxcVF4b19cASbMkdUvq3rVja423i4iIiIjYu2pNpmdSPE0eDxxay0Db36BYX/2/KZ5QP0ixhhpgVz9jltjusN3R1j62xlAjIiIiIvauqpNpSZOAecA0YCXQJamtlpvZXgi8GDgEOAC4qbz0w1rmiYiI57rhhhu44YYbmh1GRERLqeoFREljKMrYddleIWk98AAwF5hfyw1tG/hxOe+7gEeB7ww07siDx9JdZXmoiIhWdMABBzQ7hIiIllPtpi3zKV4UPBfA9mZJZwHXSFpu+35JhwAvASYASJpYjn3I9tNl2z8AXwd2A6dSPOmebrvPZR4REVG9rq4uAGbMmNHUOCIiWomKB8V76CBNBlYDU22v6XXteoq100cDXwDO7GOKY3vGSVoNHEVR2eO7wD/ZXlFNoB0dHe7u7q6ma0RES5oyZQoAa9asaWocEREjmaS7bXdU23/AJ9O21/bXz/b0itMZ5bGnuY6rNrCIiIiIiOGu1moeERERERFRSjIdERERETFISaYjIiIiIgZpwBcQB5xAGgWsAbbYPrmivR1YT/Hy4nXAHf1MMd32vw90n9HjDve4MxfVFWtExHCyqcHlPnfs2AFAe3t7Q+eNiGgltb6AWPeTadu7KV48PE7SzIpLCyheXOwEvkmxZXjlMR94GqiqmkdEROxZe3t7EumIiCFWbZ3pPbK9UVInsEjSKuAwYA4wxfb2stvmyjGSTgO+3FODOiIi6nPFFVcA8IEPfKDJkUREtI6GrZm2vRi4C1gKXA0stL2ur76SpgCvAZY06v4REa3u+uuv5/rrr292GBERLaXRLyDOBo4BngEu3EO/WcB3be9xFxZJsyR1S+retWNrA8OMiIiIiKhfo5PpmcBOYDzFzojPIemlFFuJD/hU2vYS2x22O9raxzY00IiIiIiIejUsmZY0CZgHTANWAl2S2vro+h5gN/Bvjbp3REREREQzNOQFREljgGuBLtsrJK0HHgDmUlTtqPQ3wPW2a1q3ceTBY+lucBmpiIiIiIh6NCSZpkiYxwDnAtjeLOks4BpJy23fDyDpGOAPKdZMR0REA61Zs6bZIUREtJy6l3lImgycDbzX9raedtvLgJsolnv0JO3vA75v+8567xsRERER0Wx1P5m2vba/eWxP73V+Zr33i4iIvl1++eUAdHZ2NjmSiIjW0ehqHhER0SS33HILt9xyS7PDiIhoKUmmIyIiIiIGKcl0RERERMQgDbhmWtIoYA2wxfbJFe3twHpgNbCAYsfDY4FxwBPAdcDFtndWjDkE+BfgOIrNXb4EdNr+9UBx3Pf4VibMu7XqDxYRMVxtSpnPiIh9xoDJtO3dkmYA90qaafuq8tKCcnwn8KdAGzAH+C/gDyh2OHwpZRm8cgOXW4Gnyv4vBa4BRFENJCIi6rDffvs1O4SIiJZTVTUP2xsldQKLJK0CDqNInKfY3g58vTx6bJT0ceASfltT+m3A64BX2X4UQNJc4AuSLrD9y4Z8ooiIFrVixYpmhxAR0XKqXjNtezFwF7AUuBpYaHvdHobsD/yi4vxNFDWmH61ouw0YDbyh6ogjIiIiIoaJWl9AnA0cAzxDsUa6T+Xa6E7giormg4Cf9Or6JLCrvNbXPLMkdUvq3rWjpt3HIyJaziWXXMIll1zS7DAiIlpKrcn0TIoXB8cDh/bVQdLLKZ44rwQ+3euy+5m3z3bbS2x32O5oax9bY6gREa1l1apVrFq1qtlhRES0lKqTaUmTgHnANIpEuat8qbCyz0HAHcD9wBm2K5PkzTz3CfQBFC8u9n5iHREREREx7FX1AqKkMcC1QJftFZLWAw8Ac4H5ZZ9xFIn0A8C7bD/ba5q7gA9LGm/7sbLtrRRLRu4eKIYjDx5Ld8pJRURERMQwUlUyTZEwjwHOBbC9WdJZwDWSlgM/p6hF/WPgHOAAST1jf2Z7F/ANikT7WkkfoiiNdxnw+VTyiIiIiIiRqJpNWyZT1IGeantbT7vtZZJOBbqAxcDh5fFIryleDWyyvUvSOyheSryTik1bGvA5IiJa3ktf+tJmhxAR0XL0u8uah6+Ojg53d3c3O4yIiIiI2IdJutt2R7X9a63mERERERERpSTTERH7iPPOO4/zzjuv2WFERLSUal9AjIiIYe6uu+5qdggRES1nwCfTkkZJWivp5l7t7ZI2SLpS0gRJ/yppo6Sd5c/5kvar6H+gpNsk/VjSM5IelfQvkrIbS0RERESMSAM+mba9W9IM4F5JM21fVV5aUI7vBP6UYvOVOcB/AX8ALKEofzer7L8b+CpwPsU24ocB/wJ8Hpg+UBz3Pb6VCfNurfqDRUQMN5tSKz8iYp9T1TIP2xsldQKLJK2iSITnAFNsbwe+Xh49Nkr6OHAJZTJt+ymKEno9fiTpCiAL/CIiIiJiRKp6zbTtxZJOAZYCE4CFttftYcj+wC/6uyjpFcCpwP+pNoaIiOjf+PHjmx1CRETLqfUFxNnAw+VxYX+dJB1CsfzjE31c+zLwTmA/4BbgvXuYZxblk+22/Q+sMdSIiNbyxS9+sdkhRES0nFpL482k2LlwPHBoXx0kvRy4DVgJfLqPLn8PHAX8RTnHov5uZnuJ7Q7bHW3teU8xIiIiIoaXqpNpSZOAecA0ikS5S1Jbrz4HAXcA9wNnuI/tFW1vtv0D2zcB7wdmSXplHZ8hIiKAc845h3POOafZYUREtJSqlnlIGgNcC3TZXiFpPfAAMBeYX/YZR5FIPwC8y/azVUzdk8yPrjXwiIj4Xffcc0+zQ4iIaDnVrpmeD4wBzoXi6bKks4BrJC0Hfg6sAX4MnAMcIKln7M9s75J0IkWpvLuBp4HXAZcB37L90EABHHnwWLpTVioiIiIihpEBk2lJk4Gzgam2t/W0214m6VSgi6Lk3eHl8UivKV4NbAJ+RfEC4x9QPIl+lKLu9KX1foiIiIiIiGaoZtOWtf31s1252coXBpjnduD2mqKLiIiIiBjGai2NFxERw9RrXvOaZocQEdFykkxHROwjlixZ0uwQIiJaTq11piMiIiIiojRgMi1plKS1km7u1d4uaYOkKyVNkPSvkjZK2ln+nC9pv4r+fyLpy5IeLftskPQPkpLQR0Q0wKxZs5g1a1azw4iIaCnVvIC4W9IM4F5JM21fVV5aUI7vBP4UaAPmAP9FUbFjCUUpvJ7f7G8AfgacQVHx443A54Hfo49tx3u77/GtTJh3a9UfLCKi0TYN8/KcDz74YLNDiIhoOVWtmba9UVInsEjSKuAwisR5iu3twNfLo8dGSR8HLqFMpiuS8Mo+RwGnUUUyHREREREx3FT9AqLtxZJOAZYCE4CFttftYcj+wC8GmLaaPhERERERw1Kt65VnA8cAzwAX9tdJ0iEUyz+u2EOfo4AZwJV76DNLUrek7l07ttYYakRERETE3lVrabyZwE5gPHAo8P3eHSS9HLgNWAl8uq9JJB0B3Aossv2V/m5mewnF2mtGjzvcNcYaEdFSJk6c2OwQIiJaTtXJtKRJwDzgZIr10l2S3mx7V0Wfg4DVwP3AGbafkwBLei1wB7DM9rw644+IiNKiRYuaHUJERMupapmHpDHAtUCX7RUULxUeBsyt6DMOWEPxtPpdtp/tY54/LPv8u+2/rzf4iIiIiIhmUh8Pj5/bSfo08BfAH9veVrb9JXANRcm7n1MkyT+mKH33m4rhP7O9S9LrKJ5a3wGcUzm/7c0DxdDR0eHu7u4BY42IaFV//dd/DcAXv/jFJkcSETFySbrbdke1/Qdc5iFpMnA2MLUnkQawvUzSqUAXsBg4vDwe6TXFq4FNwP8EXgacXh6/c5tqA46IiL499thjzQ4hIqLlVLNpy9r++tmeXnH6hQHm+Sjw0Rpii4iIiIgY1rKVd0RERETEICWZjoiIiIgYpFrrTEdExDD1pje9qdkhRES0nCTTERH7iPnz5zc7hIiIllNNNY9RFGXvttg+uaK9HVhPUe5uAcX24scC44AngOuAi23vrBjzGeAtwB8Bm21PqDbQ+x7fyoR5t1bbPSKiLpsufUezQ4iIiBFgwDXTtncDM4DjJM2suLSAIhnvBF4LtFHsjPg6ilJ67wE+08f9rqHYACYiIhrotNNO47TTTmt2GBERLaWqZR62N0rqBBZJWkWx++EcYIrt7cDXy6PHRkkfBy6h2C2xZ56zAcq53taYjxAREQBPPfVUs0OIiGg5Va+Ztr1Y0inAUmACsND2uj0M2R/4RT3BSZpFmYy37X9gPVNFRERERDRcraXxZgPHAM9QrJHuk6RDKJZ/XDH40MD2Etsdtjva2sfWM1VERERERMPVmkzPBHYC44FD++og6eXAbcBK4NN1RRcRERERMYxVvcxD0iRgHnAyxXrpLklvtr2ros9BFNU97gfOsO0GxxsREf04/vjjmx1CRETLUTX5rqQxFGXw1tl+X5k0PwBcbnt+2WcccEfZfrrtZ/cwXyfwwVpK43V0dLi7u7va7hERERERNZN0t+2OavtX+2R6PjAGOBfA9mZJZwHXSFoO/JyiFvWPgXOAAyT1jP1Zz9NrSYcBLwReATxf0sSyz/ds/7raoCMiIiIihoNqNm2ZTFE3eqrtbT3ttpdJOhXoAhYDh5fHI72meDWwqfznLwB/VnFtfR99IiJiEN7+9rcDsGLFiiZHEhHROgZMpm2v7a+f7ekVp1+oYq4pVUcWERE12blz58CdIiKioWqt5hEREREREaUk0xERERERg5RkOiIiIiJikKquM90fSaMoKnlssX1yRXs7xQuGq23PkfQa4JMUOyiOpiih91HbX6/mPvc9vpUJ826tN9yIYWfTpe9odgixjzjxxBObHUJERMupO5m2vVvSDOBeSTNtX1VeWlDO31me3wJsBI4HtlNsTX6TpD+0/XC9cUREtLrOzs6BO0VEREM1ZJmH7Y0USfMiSa+SdDzFLoln2t4u6QCKsnkLbH/X9kMUuyk+D3h9I2KIiIiIiBhqDVszbXsxcBewFLgaWGh7XXn5KeD7wBmSXiipDZgFbAPubFQMERGtbMqUKUyZMqXZYUREtJS6l3n0Mht4uDwu7Gm0bUlvBb4K/BLYTbFr4tttP9HfZJJmUSTdtO1/YINDjYiIiIioT6OrecwEdgLjgUN7GlXsLX4FxRPqPwXeCNwAfEXSwf1NZnuJ7Q7bHW3tYxscakREREREfRqWTEuaRLEOehqwEugql3MAHAecBLzL9p22v2P7AxQvIr63UTFERERERAylhizzkDQGuBbosr1C0nqK0ndzgflAe9l1d6+hu6kyoT/y4LF0p4RYRERERAwjjVozPR8YA5wLYHuzpLOAayQtp3gx8efA1ZIuplgK8j6KpSC3NCiGiIiWNn369GaHEBHRcmS7vgmkycBqYKrtNb2uXU+RMB8NTAQ+DnQAv0dR3eNi21XtxNLR0eHu7u66Yo2IiIiI2BNJd9vuqLZ/IzZtWdvfPLYrH5N0A39e7/0iIqJvO3bsAKC9vX2AnhER0SiNLo0XERFNcsIJJwCwZs2a5gYSEdFCGl0aLyIiIiKiZSSZjoiIiIgYpAGXeUgaBawBttg+uaK9HVgPrLY9R9IFwAkULxq221Yfcx0C/AtF3emdwJeATtu/HiiO+x7fyoR5Vb2rGNGvTSmvGBEREQ004JNp27uBGcBxkmZWXFpAkYx3luejgRuBRX3NU27gcivwIopdEN9FscHLpwYXekREREREc1X1AqLtjZI6gUWSVgGHAXOAKba3l30uApA0rZ9p3ga8DniV7UfLvnOBL0i6wPYv6/soERGtbcaMGc0OISKi5VRdzcP2YkmnAEuBCcBC2+tquNebgO/3JNKl2yieaL8BuKOGuSIiopck0xERQ6/WFxBnA8cAzwAX1jj2IOAnvdqeBHaV155D0ixJ3ZK6d+3YWuPtIiJay5NPPsmTTz7Z7DAiIlpKrcn0TIoXB8dT7GxYq/62W+yz3fYS2x22O9raxw7idhERrWPatGlMm9bfSruIiNgbqk6mJU0C5lG8NLgS6CpfKqzWZp77BPoAoI3nPrGOiIiIiBj2qlozLWkMcC3QZXuFpPXAA8BcYH6V97oL+LCk8bYfK9veSrFk5O6BBh958Fi6U9YsIiIiIoaRap9MzwfGAOcC2N4MnAV8VNIfQVFDWtJEipcTkTSxPF5YzvENigT8WkmvlzQVuAz4fCp5RERERMRINGAyLWkycDbwXtvbetptLwNuolju8TzgYopNXC4ru6wvj46y/y7gHcAO4E7gOoq61D11qiMiIiIiRpQBl3nYXttfP9vTK05nlMee5noEOLH68CIiolpz5sxpdggRES2n6jrTERExvJ1++unNDiEiouXUWhovIiKGqUcffZRHH3104I4REdEweTIdEbGPOOOMMwBYs2ZNcwOJiGghdSfTkkYBa4Attk+uaG+neAFxNUXlj/8AJgIvA34BrAL+0fbj1dznvse3MmHerfWGG/u4TSmfGBEREUOo7mUetndTvHh4nKSZFZcWUCTrPdU6VgPTgSOA0yh2UPxqvfePiIiIiGiWhizzsL1RUiewSNIq4DBgDjDF9vay26KKIT+SdClwk6Qxtn/ViDgiIiIiIoZSw9ZM214s6RRgKcXGLQttr+urr6SXAO8Gvp1EOiIiIiJGqka/gDgbeLg8Lux9UdIC4INAO/AtBqg5LWkWMAugbf8DGxxqRMS+5UMf+lCzQ4iIaDmNLo03E9gJjKdYE93bZcDrgbcBu4AvSlJ/k9leYrvDdkdb+9gGhxoRsW856aSTOOmkk5odRkRES2lYMi1pEjAPmAaspNhmvK2yj+0nbT9oeyXwl8CfA8c0KoaIiFa2YcMGNmzY0OwwIiJaSkOWeUgaA1wLdNleIWk98AAwF5jfz7CeRH50I2KIiGh173//+4HUmY6IGEqNWjM9HxgDnAtge7Oks4BrJC0HXgQcBawDtgD/DbgE2FS2DejIg8fSnRrCERERETGM1L3MQ9Jk4Gzgvba39bTbXgbcBHQBv6FY/rEaeBD4V+Be4E9TzSMiIiIiRqq6n0zbXtvfPLanV5weW++9IiIiIiKGk0ZX84iIiIiIaBmNrjMdERFN8uEPf7jZIUREtJwk0xER+4ipU6c2O4SIiJbTiBcQR0laK+nmXu3tkjZIurI8P0rSSklbJD0laYmkF9Z7/4iIKNxzzz3cc889zQ4jIqKlyHb9k0iHUlTn+FvbV5Vt/wycAPwxMBa4H/h3YCGwP7AIeML2tGruMXrc4R535qK6Y42Rb1NKJEb0acqUKUDqTEdE1EPS3bY7qu3fkGUetjdK6gQWSVoFHAbMAabY3i7p3cBu4AO2d5WBzgbulXSY7YcaEUdERERExFBq2Jpp24slnQIsBSYAC233bMgyGvhNTyJd2ln+PAZIMh0RERERI06jS+PNpkiOnwEurGhfDRwgaZ6k50v6feDS8tq4/iaTNEtSt6TuXTu2NjjUiIiIiIj6NDqZnknxxHk8cGhPo+0HgDOBc4AdwGbgh8BPgF3PmeW345bY7rDd0dY+tsGhRkRERETUp2HLPCRNAuYBJ1Osl+6S9OaepR22vwR8SdLLge2AgXMpkuqIiKjTJz7xiWaHEBHRchqSTEsaA1wLdNleIWk98AAwF5hf2df2T8oxM4FfASsbEUNERKt785vf3OwQIiJaTqOeTM8HxlA8acb2ZklnAddIWm77fkkfBL4JPA28FbgMmGd7SzU3OPLgsXSnJFpERL+++c1vAkmqIyKGUt3JtKTJwNnAVNvbetptL5N0KsVyj6OBNwL/BLwQ+AHwfttL671/REQUzj//fCB1piMihlLdybTttf3NY3t6xel76r1XRERERMRw0uhqHhERERERLSPJdERERETEICWZjoiIiIgYpAHXTEsaBawBttg+uaK9HVgPrLY9R9IFwAnARKDdtvqY6zPAW4A/AjbbntCAzxAREcCiRYuaHUJERMsZMJm2vVvSDOBeSTNtX1VeWlCO7yzPRwM3UiTe5/cz3SjgGuBI4G21BHrf41uZMO/WWobEPmhTyiNG9GvixInNDiEiouVUVc3D9kZJncAiSauAwyh2OZxie3vZ5yIASdP2MM/ZZZ9OakymIyJiz26//XYApk6d2uRIIiJaR9Wl8WwvlnQKsBSYACy0vW5vBRYREbX52Mc+BiSZjogYSrW+gDgbOAZ4Briw8eH8LkmzJHVL6t61Y+vevl1ERERERE1qTaZnAjuB8cChjQ/nd9leYrvDdkdb+9i9fbuIiIiIiJpUnUxLmgTMA6YBKym2CW/bW4FFRERERAx3VSXTksYA1wJdtlcAsyheQpy7F2OLiIiIiBjWqn0BcT4wBjgXwPZmSWcB10habvt+SYcAL6F4ORFJE8uxD9l+umw7DHgh8Arg+RV9vmf713sK4MiDx9KdsmgREf363Oc+1+wQIiJaTjWbtkwGzgam2t7W0257maRTKZZ7HA1cDJxZMXR9+fNYitrTAF8A/qyPPq8GNg0i/oiIKB1xxBHNDiEiouVUs2nL2v762Z5ecTqjPPY015TqQ4uIiFosX74cgJNOOqnJkUREtI6q60xHRMTw9qlPfQpIMh0RMZRqLY0XERERERGlJNMREREREYOUZDoiIiIiYpDqXjMtaRRFtY4ttk+uaG+nqNax2vacivYxwLeBPwYm2e6u5j73Pb6VCfNurTfcqNGmlCOMiIiI6FfdybTt3ZJmAPdKmmn7qvLSgnL+zl5DLgceo0imIyKiQZYuXdrsECIiWk5DqnnY3iipE1gkaRXF7ohzgCm2t/f0k/ROirrT04ATGnHviIgovPKVr2x2CBERLadhpfFsL5Z0CrCUYhfEhbbX9VyXNB64kiKJ3tmo+0ZEROG6664D4PTTT29yJBERraPRdaZnAw+Xx4U9jZLagH8DPmX7HkkTqplM0ixgFkDb/gc2ONSIiH3LlVdeCSSZjogYSo2u5jGT4qnzeODQivbzgd8AC2uZzPYS2x22O9raxzYuyoiIiIiIBmhYMi1pEjCPYj30SqCrfCINcDzFWunfSHoWeKhs/5akf2tUDBERERERQ6khyzzKcnfXAl22V0haDzwAzAXmA+8FXlAx5BXAbcC7gTuruceRB4+lO2XaIiIiImIYadSa6fnAGOBcANubJZ0FXCNpue37KztLerr8x4dtP9agGCIiIiIihlQjNm2ZDJwNTLW9rafd9jJJp1Is9zja9rP13isiIvp3ww03NDuEiIiW04hNW9b2N4/t6f20bwJU770jIuK3DjjggGaHEBHRchpdzSMiIpqkq6uLrq6uZocREdFSkkxHROwjkkxHRAy9JNMREREREYPUiBcQRwFrgC22T65obwfWA6uBBRQ7Ih4LjAOeAK4DLrZd1dbi9z2+lQnzbq033Ja2KaUFIyIiIhqq7ifTtncDM4DjJM2suLSAIlnvBF4LtAFzgNdRVP94D/CZeu8fEREREdEsDakzbXujpE5gkaRVwGEUifMU29uBr5dHj42SPg5cAsxqRAwREREREUOtUZu2YHuxpFOApcAEYKHtdXsYsj/wi0bdPyKi1X3ta19rdggRES2nYcl0aTbwcHlc2F8nSYdQLP/4xJ4mkzSL8sl12/4HNi7KiIh9UHt7e7NDiIhoOY2u5jET2AmMBw7tq4OklwO3ASuBT+9pMttLbHfY7mhrH9vgUCMi9i1XXHEFV1xxRbPDiIhoKQ1LpiVNAuYB0ygS5S5Jbb36HATcAdwPnGHbjbp/RESru/7667n++uubHUZEREtpyDIPSWOAa4Eu2yskrQceAOYC88s+4ygS6QeAd9l+tpZ7HHnwWLpT2i0iIiIihpFGrZmeD4wBzgWwvVnSWcA1kpYDP6eoRf1j4BzgAEk9Y39me1eD4oiIiIiIGDKN2LRlMkXd6Km2t/W0214m6VSgC1gMHF4ej/Sa4tXApnrjiIiIiIgYanUn07bX9jeP7ekVp1+o914REREREcOJRso7gJK2ARuaHUcMGwcATzY7iBhW8p2I3vKdiEr5PkRv/X0nXmW76prMja4zvTdtsN3R7CBieJDUne9DVMp3InrLdyIq5fsQvTXqO9HoOtMRERERES0jyXRERERExCCNpGR6SbMDiGEl34foLd+J6C3fiaiU70P01pDvxIh5ATEiIiIiYrgZSU+mIyIiIiKGlaYn05L+h6QNkh6SNK+P65L02fL6vZKOqnZsjEyD/U5IeqWkOyR9X9IDkv5u6KOPRqvnd0R5vU3Sekm3DF3UsTfV+d+NF0u6QdIPyt8Vbxra6GNvqPM78fflfzPul/RlSWOGNvpotCq+D6+VdJekZyR11jK2T7abdgBtwMPAocDzge8Cf9irzwnACkDA0cC3qx2bY+QddX4nxgFHlf/8IuDBfCdG9lHP96Hi+rnAl4Bbmv15cjT/OwFcA/xN+c/PB17c7M+Uo3nfCeBg4IfAfuX59cCMZn+mHHv9+/AyYBLwcaCzlrF9Hc1+Mv1G4CHbG23/GlgGvLNXn3cC17rwLeDFksZVOTZGnkF/J2w/Yfs7AC62tv8+xS/KGLnq+R2BpPHAO8gOrPuSQX8nJO0PTAb+FcD2r21vGcLYY++o6/cExZ4b+0l6HtAO/HioAo+9YsDvg+2f2v5P4De1ju1Ls5Ppg4FHK84f47nJT399qhkbI08934n/n6QJwOuBbzc+xBhC9X4fFgFzgd17Kb4YevV8Jw4FfgZcXS79+YKkF+zNYGNIDPo7Yftx4HLgEeAJYKvtb+zFWGPvqyc/HNTYZifT6qOtd3mR/vpUMzZGnnq+E8VF6YXAV4BzbP+ygbHF0Bv090HSicBPbd/d+LCiier5HfE84CjgStuvB7YDed9m5Kvn98TvUzx5fDXwCuAFkv66wfHF0KonPxzU2GYn048Br6w4H89z/3qlvz7VjI2Rp57vBJJ+jyKR/jfbN+7FOGNo1PN9eAtwsqRNFH9Vd5ykL+69UGOI1Pvfjcds9/yN1Q0UyXWMbPV8J6YCP7T9M9u/AW4E3rwXY429r578cFBjm51M/ydwuKRXS3o+8JfAzb363Ay8p3wT92iKv4J5osqxMfIM+jshSRRrIb9ve+HQhh17yaC/D7bPsz3e9oRy3GrbeeI08tXzndgMPCrpiLLf8cD3hizy2FvqySUeAY6W1F7+N+R4ivdtYuSqJz8c1NjnDTrUBrD9rKQPArdRvEF5le0HJM0ury8GvkbxFu5DwA7gvXsa24SPEQ1Uz3eC4knkGcB9ku4p2863/bUh/AjRQHV+H2If1IDvxNnAv5X/odxIvi8jXp25xLcl3QB8B3gWWE92ShzRqvk+SDoI6Ab2B3ZLOoeiascvB5NbZgfEiIiIiIhBavYyj4iIiIiIESvJdERERETEICWZjoiIiIgYpCTTERERERGDlGQ6IiIiImKQkkxHRERERAxSkumIiIiIiEFKMh0RERERMUj/H0jOKL+sFHtHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,6))\n",
    "feature_importances.sort_values().plot.barh(ax=ax);\n",
    "ax.set_yticklabels(ax.get_yticklabels(),fontsize=14);\n",
    "ax.set_title('Feature Importance', fontsize=15);\n",
    "plt.axvline(x=0.05, color='k', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select features: Index(['X1', 'X5', 'X6', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18',\n",
      "       'X19', 'X20', 'X21', 'X23'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# SelectFromModel\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(logr,threshold=None, prefit=True)\n",
    "sfm.get_support() # boolean mask of features selected\n",
    "X_train.columns[sfm.get_support()]\n",
    "X_train_subset = sfm.transform(X_train)\n",
    "\n",
    "sfm_rf = SelectFromModel(RandomForestClassifier(), threshold='mean',prefit=False).fit(X_train,y_train)\n",
    "print(f'select features: {X_train.columns[sfm_rf.get_support()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X6', 'X7', 'X8']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate tests\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# select 3 best features\n",
    "kbest = SelectKBest(score_func=f_classif, k=3).fit(X_train, y_train)\n",
    "list(X.columns[kbest.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X6', 'X12', 'X13'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(LogisticRegression(penalty='none'), n_features_to_select=3, step=1).fit(X_train,y_train)\n",
    "X_train.columns[rfe.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28435067 0.17862594 0.06936422]\n"
     ]
    }
   ],
   "source": [
    "# Principal Component Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit and transform the X_train to 3d using pca\n",
    "pca = PCA(n_components=3, random_state=123)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_train_pca = pd.DataFrame(X_train_pca,columns=['component1','component2','component3'])\n",
    "\n",
    "# Transform the X_test to 3d using pca\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_test_pca = pd.DataFrame(X_test_pca,columns=['component1','component2','component3'])\n",
    "# Print the ratio of variance explained by each component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Build and Evaluate Advanced Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV,RepeatedStratifiedKFold,cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import scipy.io\n",
    "import pickle\n",
    "import os, sys\n",
    "from scipy.spatial.distance import pdist\n",
    "import time \n",
    "import xlsxwriter\n",
    "from sklearn.metrics import accuracy_score, classification_report,make_scorer, confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \n",
    "grid_svm = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid_svm.fit(X_train,y_train)\n",
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 435.366 seconds\n",
      "Accuracy of SVM on test set: 0.821\n",
      "Predicting test data takes 18.239 seconds\n",
      "Classification error rate: 0.17866666666666667\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.72      0.32      0.44      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.78      0.64      0.67      6000\n",
      "weighted avg       0.81      0.82      0.79      6000\n",
      "\n",
      "Confusion Matrix \n",
      " [[4509  164]\n",
      " [ 908  419]]\n",
      "AUC is: 0.7253\n"
     ]
    }
   ],
   "source": [
    "#Train SVM using best parameters\n",
    "svm_best = SVC(C=10,gamma=0.01,kernel='rbf',probability=True) \n",
    "start_time=time.time()\n",
    "svm_best.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start_time),3))\n",
    "print('Accuracy of SVM on test set: {:.3f}'.format(svm_best.score(X_test,y_test)))\n",
    "\n",
    "start = time.time()\n",
    "svm_pred = svm_best.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "svm_predprob = svm_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print('Classification error rate:', np.mean(np.array(y_test)!= svm_pred))\n",
    "print('Classification report \\n', classification_report(y_test, svm_pred))\n",
    "\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, svm_pred))\n",
    "print('AUC is: {:.4f}'.format(roc_auc_score(y_test, svm_predprob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.01, probability=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save trained SVM model\n",
    "pickle.dump(svm_best, open(\"../output/best_svm.p\",'wb'))\n",
    "#Load SVM balanced model\n",
    "pickle.load(open(\"../output/best_svm.p\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Weighted SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_svm():\n",
    "    weighted_svm = SVC(gamma = 'scale', class_weight = 'balanced')\n",
    "\n",
    "    #CV Weighted SVM \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(weighted_svm, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    # summarize performance\n",
    "    print('Mean ROC AUC: %.3f' % np.mean(scores))\n",
    "\n",
    "    # parameter space for the model\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']} \n",
    "\n",
    "    grid_svm = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "    grid_svm.fit(X_train,y_train)\n",
    "    \n",
    "    print(grid_svm.best_params_)\n",
    "    print(grid_svm.best_estimator_)\n",
    "    \n",
    "    balance = [{0:598.0, 1:2402.0},{0:1,1:100}, {0:1,1:10}, {0:1,1:1}, {0:10,1:1}, {0:100,1:1}]\n",
    "    param_grid = dict(class_weight=balance)\n",
    "\n",
    "    grid_weightedsvm = GridSearchCV(estimator=weighted_svm, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "    grid_weightedsvm.fit(X_train, y_train)\n",
    "    grid_weightedsvm.best_params_\n",
    "    grid_weightedsvm.best_estimator_\n",
    "    grid_weightedsvm.best_params_\n",
    "    grid_weightedsvm.best_estimator_\n",
    "    \n",
    "    print(\"Best: %f using %s\" % (grid_weightedsvm.best_score_, grid_weightedsvm.best_params_))\n",
    "    \n",
    "    # report all configurations\n",
    "    means = grid_weightedsvm.cv_results_['mean_test_score']\n",
    "    stds = grid_weightedsvm.cv_results_['std_test_score']\n",
    "    params = grid_weightedsvm.cv_results_['params']\n",
    "    \n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.758\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END .....................C=0.1, gamma=1, kernel=rbf; total time= 2.9min\n",
      "[CV 2/5] END .....................C=0.1, gamma=1, kernel=rbf; total time= 2.8min\n",
      "[CV 3/5] END .....................C=0.1, gamma=1, kernel=rbf; total time= 2.5min\n",
      "[CV 4/5] END .....................C=0.1, gamma=1, kernel=rbf; total time= 2.8min\n",
      "[CV 5/5] END .....................C=0.1, gamma=1, kernel=rbf; total time= 2.5min\n",
      "[CV 1/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time= 1.1min\n",
      "[CV 2/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  54.4s\n",
      "[CV 3/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  52.1s\n",
      "[CV 4/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=  52.0s\n",
      "[CV 5/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time= 1.1min\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  58.4s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  51.4s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  52.1s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  53.6s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=  55.4s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  59.7s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  55.5s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=  57.6s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time= 1.0min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time= 1.0min\n",
      "[CV 1/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time=  58.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time= 1.0min\n",
      "[CV 3/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time= 1.1min\n",
      "[CV 4/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time= 1.1min\n",
      "[CV 5/5] END ................C=0.1, gamma=0.0001, kernel=rbf; total time= 1.2min\n",
      "[CV 1/5] END .......................C=1, gamma=1, kernel=rbf; total time= 4.4min\n",
      "[CV 2/5] END .......................C=1, gamma=1, kernel=rbf; total time= 4.3min\n",
      "[CV 3/5] END .......................C=1, gamma=1, kernel=rbf; total time= 3.3min\n",
      "[CV 4/5] END .......................C=1, gamma=1, kernel=rbf; total time= 3.2min\n",
      "[CV 5/5] END .......................C=1, gamma=1, kernel=rbf; total time= 4.3min\n",
      "[CV 1/5] END .....................C=1, gamma=0.1, kernel=rbf; total time= 2.4min\n",
      "[CV 2/5] END .....................C=1, gamma=0.1, kernel=rbf; total time= 2.5min\n",
      "[CV 3/5] END .....................C=1, gamma=0.1, kernel=rbf; total time= 2.0min\n",
      "[CV 4/5] END .....................C=1, gamma=0.1, kernel=rbf; total time= 1.6min\n",
      "[CV 5/5] END .....................C=1, gamma=0.1, kernel=rbf; total time= 1.6min\n",
      "[CV 1/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  54.6s\n",
      "[CV 2/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  47.4s\n",
      "[CV 3/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  46.9s\n",
      "[CV 4/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  47.2s\n",
      "[CV 5/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  46.4s\n",
      "[CV 1/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  45.5s\n",
      "[CV 2/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  45.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  45.1s\n",
      "[CV 4/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  45.0s\n",
      "[CV 5/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=  46.0s\n",
      "[CV 1/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  47.2s\n",
      "[CV 2/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  42.3s\n",
      "[CV 3/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  42.4s\n",
      "[CV 4/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  43.5s\n",
      "[CV 5/5] END ..................C=1, gamma=0.0001, kernel=rbf; total time=  45.6s\n",
      "[CV 1/5] END ......................C=10, gamma=1, kernel=rbf; total time= 3.6min\n",
      "[CV 2/5] END ......................C=10, gamma=1, kernel=rbf; total time= 3.0min\n",
      "[CV 3/5] END ......................C=10, gamma=1, kernel=rbf; total time= 3.1min\n",
      "[CV 4/5] END ......................C=10, gamma=1, kernel=rbf; total time= 2.9min\n",
      "[CV 5/5] END ......................C=10, gamma=1, kernel=rbf; total time= 2.9min\n",
      "[CV 1/5] END ....................C=10, gamma=0.1, kernel=rbf; total time= 2.3min\n",
      "[CV 2/5] END ....................C=10, gamma=0.1, kernel=rbf; total time= 2.5min\n",
      "[CV 3/5] END ....................C=10, gamma=0.1, kernel=rbf; total time= 2.4min\n",
      "[CV 4/5] END ....................C=10, gamma=0.1, kernel=rbf; total time= 2.4min\n",
      "[CV 5/5] END ....................C=10, gamma=0.1, kernel=rbf; total time= 2.4min\n",
      "[CV 1/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  56.0s\n",
      "[CV 2/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  56.2s\n",
      "[CV 3/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  57.2s\n",
      "[CV 4/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  56.0s\n",
      "[CV 5/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=  56.8s\n",
      "[CV 1/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  49.3s\n",
      "[CV 2/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  48.7s\n",
      "[CV 3/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  51.1s\n",
      "[CV 4/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  53.6s\n",
      "[CV 5/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=  47.2s\n",
      "[CV 1/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  43.6s\n",
      "[CV 2/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  43.3s\n",
      "[CV 3/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  42.8s\n",
      "[CV 4/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  42.7s\n",
      "[CV 5/5] END .................C=10, gamma=0.0001, kernel=rbf; total time=  43.4s\n",
      "[CV 1/5] END .....................C=100, gamma=1, kernel=rbf; total time= 3.4min\n",
      "[CV 2/5] END .....................C=100, gamma=1, kernel=rbf; total time= 3.5min\n",
      "[CV 3/5] END .....................C=100, gamma=1, kernel=rbf; total time= 4.7min\n",
      "[CV 4/5] END .....................C=100, gamma=1, kernel=rbf; total time= 4.8min\n",
      "[CV 5/5] END .....................C=100, gamma=1, kernel=rbf; total time= 4.7min\n",
      "[CV 1/5] END ...................C=100, gamma=0.1, kernel=rbf; total time= 6.4min\n",
      "[CV 2/5] END ...................C=100, gamma=0.1, kernel=rbf; total time= 5.9min\n",
      "[CV 3/5] END ...................C=100, gamma=0.1, kernel=rbf; total time= 5.8min\n",
      "[CV 4/5] END ...................C=100, gamma=0.1, kernel=rbf; total time= 5.8min\n",
      "[CV 5/5] END ...................C=100, gamma=0.1, kernel=rbf; total time= 5.5min\n",
      "[CV 1/5] END ..................C=100, gamma=0.01, kernel=rbf; total time= 2.3min\n",
      "[CV 2/5] END ..................C=100, gamma=0.01, kernel=rbf; total time= 2.0min\n",
      "[CV 3/5] END ..................C=100, gamma=0.01, kernel=rbf; total time= 1.8min\n",
      "[CV 4/5] END ..................C=100, gamma=0.01, kernel=rbf; total time= 1.8min\n",
      "[CV 5/5] END ..................C=100, gamma=0.01, kernel=rbf; total time= 2.3min\n",
      "[CV 1/5] END .................C=100, gamma=0.001, kernel=rbf; total time= 1.3min\n",
      "[CV 2/5] END .................C=100, gamma=0.001, kernel=rbf; total time= 1.2min\n",
      "[CV 3/5] END .................C=100, gamma=0.001, kernel=rbf; total time= 1.2min\n",
      "[CV 4/5] END .................C=100, gamma=0.001, kernel=rbf; total time= 1.3min\n",
      "[CV 5/5] END .................C=100, gamma=0.001, kernel=rbf; total time= 1.3min\n",
      "[CV 1/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  55.1s\n",
      "[CV 2/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  52.7s\n",
      "[CV 3/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  55.3s\n",
      "[CV 4/5] END ................C=100, gamma=0.0001, kernel=rbf; total time= 1.0min\n",
      "[CV 5/5] END ................C=100, gamma=0.0001, kernel=rbf; total time=  57.9s\n",
      "[CV 1/5] END ....................C=1000, gamma=1, kernel=rbf; total time= 4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....................C=1000, gamma=1, kernel=rbf; total time= 3.9min\n",
      "[CV 3/5] END ....................C=1000, gamma=1, kernel=rbf; total time= 4.2min\n",
      "[CV 4/5] END ....................C=1000, gamma=1, kernel=rbf; total time= 3.9min\n",
      "[CV 5/5] END ....................C=1000, gamma=1, kernel=rbf; total time= 4.6min\n",
      "[CV 1/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=14.0min\n",
      "[CV 2/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=10.2min\n",
      "[CV 3/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=10.6min\n",
      "[CV 4/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=11.1min\n",
      "[CV 5/5] END ..................C=1000, gamma=0.1, kernel=rbf; total time=10.8min\n",
      "[CV 1/5] END .................C=1000, gamma=0.01, kernel=rbf; total time=10.0min\n",
      "[CV 2/5] END .................C=1000, gamma=0.01, kernel=rbf; total time= 9.0min\n",
      "[CV 3/5] END .................C=1000, gamma=0.01, kernel=rbf; total time= 8.5min\n",
      "[CV 4/5] END .................C=1000, gamma=0.01, kernel=rbf; total time= 7.3min\n",
      "[CV 5/5] END .................C=1000, gamma=0.01, kernel=rbf; total time= 8.6min\n",
      "[CV 1/5] END ................C=1000, gamma=0.001, kernel=rbf; total time= 3.5min\n",
      "[CV 2/5] END ................C=1000, gamma=0.001, kernel=rbf; total time= 3.4min\n",
      "[CV 3/5] END ................C=1000, gamma=0.001, kernel=rbf; total time= 3.2min\n",
      "[CV 4/5] END ................C=1000, gamma=0.001, kernel=rbf; total time= 2.7min\n",
      "[CV 5/5] END ................C=1000, gamma=0.001, kernel=rbf; total time= 2.7min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time= 1.1min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time= 1.1min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time=  59.8s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time= 1.1min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.0001, kernel=rbf; total time= 1.1min\n",
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.01)\n",
      "Best: 0.721981 using {'class_weight': {0: 1, 1: 1}}\n",
      "0.681255 (0.013893) with: {'class_weight': {0: 598.0, 1: 2402.0}}\n",
      "0.618916 (0.012968) with: {'class_weight': {0: 1, 1: 100}}\n",
      "0.720247 (0.010599) with: {'class_weight': {0: 1, 1: 10}}\n",
      "0.721981 (0.013200) with: {'class_weight': {0: 1, 1: 1}}\n",
      "0.607890 (0.014923) with: {'class_weight': {0: 10, 1: 1}}\n",
      "0.605034 (0.014852) with: {'class_weight': {0: 100, 1: 1}}\n"
     ]
    }
   ],
   "source": [
    " fine_tune_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  model takes 366.52 seconds\n",
      "Testing Accuracy of weighted SVM on test set: 0.821\n",
      "Predicting test data takes 12.705 seconds\n",
      "Classification error rate: 0.1795\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.70      0.33      0.45      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.77      0.64      0.67      6000\n",
      "weighted avg       0.80      0.82      0.79      6000\n",
      "\n",
      "Confusion Matrix \n",
      " [[4486  187]\n",
      " [ 890  437]]\n",
      "AUC is: 0.7271\n"
     ]
    }
   ],
   "source": [
    "weighted_svm_best = SVC(\n",
    "        gamma = 'scale',\n",
    "        class_weight = {\n",
    "            0: 1, \n",
    "            1: 1\n",
    "        },\n",
    "        probability=True\n",
    "    )\n",
    "start1 = time.time()\n",
    "    \n",
    "    # fit svm model\n",
    "weighted_svm_best.fit(X_train, y_train)\n",
    "    \n",
    "print(\"Training  model takes %s seconds\" % round((time.time() - start1),3))\n",
    "print('Testing Accuracy of weighted SVM on test set: {:.3f}'\n",
    "          .format(weighted_svm_best.score(X_test,y_test)))\n",
    "    \n",
    "start = time.time()\n",
    "    \n",
    "    # make prediction\n",
    "weighted_svm_pred = weighted_svm_best.predict(X_test)\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "weighted_svm_predprob = weighted_svm_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Predicting test data takes %s seconds\" % round((end - start),3))\n",
    "print('Classification error rate:', np.mean(np.array(y_test) != weighted_svm_pred))\n",
    "print('Classification report \\n', classification_report(y_test, weighted_svm_pred))\n",
    "\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test, weighted_svm_pred))\n",
    "print('AUC is: {:.4f}'.format(roc_auc_score(y_test, weighted_svm_predprob)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight={0: 1, 1: 1}, probability=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Advanced Model\n",
    "pickle.dump(weighted_svm_best, open(\"../output/best_weighted_svm.p\",'wb'))\n",
    "\n",
    "#Load weighted SVM model\n",
    "pickle.load(open(\"../output/best_weighted_svm.p\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
